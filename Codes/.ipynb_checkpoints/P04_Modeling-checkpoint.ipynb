{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import eli5\n",
    "\n",
    "import regex as re\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent</th>\n",
       "      <th>text_merged</th>\n",
       "      <th>word_count*</th>\n",
       "      <th>sentiment_score*</th>\n",
       "      <th>target</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_VSA</th>\n",
       "      <th>lower_sent</th>\n",
       "      <th>tagged_sent</th>\n",
       "      <th>text_complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>star shine saturn ring</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>star shine saturn ring</td>\n",
       "      <td>[(star, NN), (shine, NN), (saturn, NN), (ring,...</td>\n",
       "      <td>92.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>smithsonian nation air space museum</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>smithsonian nation air space museum</td>\n",
       "      <td>[(smithsonian, JJ), (nation, NN), (air, NN), (...</td>\n",
       "      <td>15.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ent                          text_merged  word_count*  sentiment_score*  \\\n",
       "0    1               star shine saturn ring            4               0.0   \n",
       "1    2  smithsonian nation air space museum            5               0.0   \n",
       "\n",
       "   target  polarity_score  polarity  polarity_VSA  \\\n",
       "0       1             0.0         1             1   \n",
       "1       1             0.0         1             1   \n",
       "\n",
       "                            lower_sent  \\\n",
       "0               star shine saturn ring   \n",
       "1  smithsonian nation air space museum   \n",
       "\n",
       "                                         tagged_sent  text_complexity  \n",
       "0  [(star, NN), (shine, NN), (saturn, NN), (ring,...            92.80  \n",
       "1  [(smithsonian, JJ), (nation, NN), (air, NN), (...            15.64  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_reddit = pickle.load(open('../DataSet/df_reddit_for_model.pkl', 'rb'))\n",
    "df_reddit = pickle.load(open('../DataSet/df_reddit_for_model.pkl', 'rb'))\n",
    "EDA_df = pickle.load(open('../DataSet/EDA_all_for_model.pkl', 'rb'))\n",
    "# df_reddit['target'] = df_reddit['subreddit'].replace({\"NASA\": 1, \"Space_discussion\": 0})\n",
    "df_reddit.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>''</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>ent</th>\n",
       "      <th>word_count*</th>\n",
       "      <th>sentiment_score*</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_VSA</th>\n",
       "      <th>text_complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target   ''   CC   CD   DT   EX   FW   IN   JJ  JJR       ...          WP  \\\n",
       "0       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       ...         0.0   \n",
       "1       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0       ...         0.0   \n",
       "\n",
       "   WP$  WRB  ent  word_count*  sentiment_score*  polarity_score  polarity  \\\n",
       "0  0.0  0.0    1            4               0.0             0.0         1   \n",
       "1  0.0  0.0    2            5               0.0             0.0         1   \n",
       "\n",
       "   polarity_VSA  text_complexity  \n",
       "0             1            92.80  \n",
       "1             1            15.64  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDA_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining X and Y variables and use train test split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reddit['text_merged']\n",
    "y = df_reddit['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(min_df=4, max_df=1.0,\n",
    "                       ngram_range=(1,2),max_features = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_mat = cvec.fit_transform(df_reddit['text_merged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_df = pd.DataFrame(term_mat.toarray(), \n",
    "                       columns=cvec.get_feature_names())\n",
    "term_df.insert(0, 'targets', df_reddit['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targets</th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abl see</th>\n",
       "      <th>aboard</th>\n",
       "      <th>aboard intern</th>\n",
       "      <th>aboard space</th>\n",
       "      <th>abort</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>youlikebet</th>\n",
       "      <th>young</th>\n",
       "      <th>youtu</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero graviti</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zubrin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   targets  aa  ab  abil  abl  abl see  aboard  aboard intern  aboard space  \\\n",
       "0        1   0   0     0    0        0       0              0             0   \n",
       "1        1   0   0     0    0        0       0              0             0   \n",
       "2        1   0   0     0    0        0       0              0             0   \n",
       "3        1   0   0     0    0        0       0              0             0   \n",
       "4        1   0   0     0    0        0       0              0             0   \n",
       "\n",
       "   abort   ...    york  youlikebet  young  youtu  zealand  zero  zero graviti  \\\n",
       "0      0   ...       0           0      0      0        0     0             0   \n",
       "1      0   ...       0           0      0      0        0     0             0   \n",
       "2      0   ...       0           0      0      0        0     0             0   \n",
       "3      0   ...       0           0      0      0        0     0             0   \n",
       "4      0   ...       0           0      0      0        0     0             0   \n",
       "\n",
       "   zone  zoom  zubrin  \n",
       "0     0     0       0  \n",
       "1     0     0       0  \n",
       "2     0     0       0  \n",
       "3     0     0       0  \n",
       "4     0     0       0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8365555555555556\n",
      "test score 0.7473333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train_features = cvec.fit_transform(X_train)\n",
    "X_test_features = cvec.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(solver='sag', \n",
    "                        max_iter=3000)\n",
    "\n",
    "lr.fit(X_train_features, y_train);\n",
    "\n",
    "lr.score(X_train_features, y_train); \n",
    "print('train score', lr.score(X_train_features, y_train))\n",
    "\n",
    "lr.score(X_test_features, y_test); \n",
    "print('test score', lr.score(X_test_features, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.12, 'max_depth': 4, 'n_estimators': 150}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                                    n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "                                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                    max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                    init=None, random_state=None, max_features=None, verbose=0, \n",
    "                                    max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, \n",
    "                                    n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "gboost_params = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'n_estimators': [100, 125, 150],\n",
    "    'learning_rate': [.08, .1, .12]\n",
    "}\n",
    "gs = GridSearchCV(gboost, param_grid=gboost_params, cv=3)\n",
    "gs.fit(X_train_features, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going with the best hyperparameters for gboost. Notice grid search convergence to max values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier(loss='deviance', learning_rate=0.12, \n",
    "                                    n_estimators=150, subsample=1.0, criterion='friedman_mse', \n",
    "                                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                    max_depth=4, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                    init=None, random_state=None, max_features=None, verbose=0, \n",
    "                                    max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, \n",
    "                                    n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "gboost.fit(X_train_features, y_train)\n",
    "print(gboost.score(X_test_features, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7445555555555555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh', 'hidden_layer_sizes': 50, 'solver': 'sgd'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=50, activation='relu', solver='adam', \n",
    "                    alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                    learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "                    random_state=None, tol=0.0001, verbose=False, warm_start=False, \n",
    "                    momentum=0.9, nesterovs_momentum=True, early_stopping=False, \n",
    "                    validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "                    n_iter_no_change=10, max_fun=15000)\n",
    "\n",
    "\n",
    "mlp_params = {\n",
    "    'hidden_layer_sizes': [20,50,100],\n",
    "    'activation': ['identity', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam']\n",
    "}\n",
    "mlpg = GridSearchCV(mlp, param_grid=mlp_params, cv=3)\n",
    "mlpg.fit(X_train_features, y_train)\n",
    "\n",
    "\n",
    "print(mlpg.best_score_)\n",
    "mlpg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7526666666666667\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=50, activation='tanh', solver='sgd', \n",
    "                    alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                    learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "                    random_state=None, tol=0.0001, verbose=False, warm_start=False, \n",
    "                    momentum=0.9, nesterovs_momentum=True, early_stopping=False, \n",
    "                    validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "                    n_iter_no_change=10, max_fun=15000)\n",
    "\n",
    "\n",
    "mlpg.fit(X_train_features, y_train)\n",
    "print(mlpg.score(X_test_features, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use EDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>''</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>ent</th>\n",
       "      <th>word_count*</th>\n",
       "      <th>sentiment_score*</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_VSA</th>\n",
       "      <th>text_complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target   ''   CC   CD   DT   EX   FW   IN   JJ  JJR       ...          WP  \\\n",
       "0       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       ...         0.0   \n",
       "1       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0       ...         0.0   \n",
       "\n",
       "   WP$  WRB  ent  word_count*  sentiment_score*  polarity_score  polarity  \\\n",
       "0  0.0  0.0    1            4               0.0             0.0         1   \n",
       "1  0.0  0.0    2            5               0.0             0.0         1   \n",
       "\n",
       "   polarity_VSA  text_complexity  \n",
       "0             1            92.80  \n",
       "1             1            15.64  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDA_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = EDA_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = EDA_df.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr = np.array(X)\n",
    "y_arr = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_arr,\n",
    "                                                    y_arr,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.825\n",
      "test score 0.8276666666666667\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='sag', \n",
    "                        max_iter=5000)\n",
    "\n",
    "lr.fit(X_train, y_train);\n",
    "\n",
    "lr.score(X_train, y_train); \n",
    "print('train score', lr.score(X_train, y_train))\n",
    "\n",
    "lr.score(X_test, y_test); \n",
    "print('test score', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8276666666666667, 0.9685414680648237, 0.6773333333333333)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lr.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test_features, y_test, cmap='Blues', values_format='d');\n",
    "Accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "Precision = tp / (tp + fp)\n",
    "Recall = tp / (tp + fn)\n",
    "\n",
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8344444444444444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                                    n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "                                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                    max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                    init=None, random_state=None, max_features=None, verbose=0, \n",
    "                                    max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, \n",
    "                                    n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "gboost_params = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'n_estimators': [100, 125, 150],\n",
    "    'learning_rate': [.08, .1, .12]\n",
    "}\n",
    "gs = GridSearchCV(gboost, param_grid=gboost_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and going down with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8353333333333334\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier(loss='deviance', learning_rate=0.08, \n",
    "                                    n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "                                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                    max_depth=2, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                    init=None, random_state=None, max_features=None, verbose=0, \n",
    "                                    max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, \n",
    "                                    n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "gboost.fit(X_train, y_train)\n",
    "print(gboost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8353333333333334, 1.0, 0.6706666666666666)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gboost.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test_features, y_test, cmap='Blues', values_format='d');\n",
    "Accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "Precision = tp / (tp + fp)\n",
    "Recall = tp / (tp + fn)\n",
    "\n",
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets apply ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20,20,10), activation='tanh', solver='sgd', \n",
    "                    alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                    learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "                    random_state=None, tol=0.0001, verbose=False, warm_start=False, \n",
    "                    momentum=0.9, nesterovs_momentum=True, early_stopping=False, \n",
    "                    validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "                    n_iter_no_change=10, max_fun=15000)\n",
    "\n",
    "\n",
    "mlpg.fit(X_train, y_train)\n",
    "print(mlpg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8333333333333334, 0.9901960784313726, 0.6733333333333333)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = mlpg.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test_features, y_test, cmap='Blues', values_format='d');\n",
    "Accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "Precision = tp / (tp + fp)\n",
    "Recall = tp / (tp + fn)\n",
    "\n",
    "Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
